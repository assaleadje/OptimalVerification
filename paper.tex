 \documentclass[10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{version}


\allowdisplaybreaks
 \newcommand\ForAuthors[1]%          %  temporary remark for the
 {\par\smallskip                     %  authors:
  \begin{center}%                    %
   \fbox%                            %    --------
   {\parbox{0.9\linewidth}%          %    |  #1  |
    {\raggedright\sc--- #1}%         %    --------
   }%                                %
  \end{center}%                      %
  \par\smallskip                     %
 }

\input{raccourcis}

\title{Optimal analysis of Discrete-time Time-Invariant Affine Systems}
\author{Assalé Adjé}
\date{}%

\begin{document}
\maketitle
\section{Introduction}
Goal of verification : some catastrophic events\ForAuthors{citer quelques evenements catastrophiques} caused by bugs in programs leaded to a new branch in computer science called formal verification of programs\ForAuthors{trouver une citation sur les premiers travaux en verification}. Formal verification provides a deeper analysis compared to traditional test techniques. Indeed, tests cannot cover all possible situation. The principle of formal verification consists in an exhaustive approach to prove properties on programs. Various techniques exist but none of them cannot be complete. 

Numerical programs in an ideal world can be viewed as a discrete-time dynamical systems. Some numerical
programs comes from discretization or linearization techniques. Thus linear systems forms a huge class of interesting problems. 


During the last twenty years,  the verification of linear systems techniques evolve and propose new challenges. Classical approaches come from theoretical computer science. Those approaches are based on static analysis such as model-checking or abstract interpretation. 
The goal of the paper is to offer a complete analysis of discrete-time linear systems.
Indeed, the static analysis of such systems based on abstract interpretation can prove 
valid properties. However, because abstractions and the presence of false alarms, the challenge which consists in invalidating properties remains extremely difficult for analyzers. The problem addressed here can be reduced to maximize a function over the reachable values set of a dynamical system.
The method developed here consists in replacing an infinite numbers of maximization problems by a finite number of them.  We propose to compute an integer after which we know that the optimal value cannot be reached. 

\section{Notations}
In this paper, we denote by $\Idd$ the identity matrix of size $d\times d$. We denote, for a matrix $M$, by $M^\intercal$ the transpose of $M$. The set of the (square) symmetric matrices  (the matrices $M$ such that $M=M^\intercal$) of size $d$ is denoted by $\sym$.  

We recall that a matrix $M$ of size $d\times d$ is {\it positive semidefinite} if and only if $M$ is symmetric for all $x\in\rd$,
$x^\intercal M x\geq 0$. Whereas the matrix $M$ is said to positive definite if and only if $M$ is symmetric for all $x\in\rd$, $x\neq 0$, 
$x^\intercal M x>0$. An equivalent definition relies on eigenvalues (for a square matrix $M$, the complex values $\lambda$ such that $Ax=\lambda x$ for some non zero $x$) and a matrix is positive semidefinite (resp. definite) if and only if all eigenvalues are non-negative (resp. positive); recalling that the eigenvalues of a symmetric matrix are real.
Finally, a matrix $M$ is negative semidefinite (resp. definite) if $-M$ is positive semidefinite (resp. definite).
We will write $M\succeq 0$ (resp. $M\succ 0$)  when $M$ is positive semi-definite (resp. definite).

For a given symmetric matrix $M$ of size $d$ , we will consider the real eigenvalues in descending order   $\lmax{M}=\lambda_1(M)\geq \lambda_2(M)\geq \ldots\geq \lambda_d(M)=\lmin{M}$. Moreover, we denote by $\rho(M)$ the spectral radius of a square matrix $M$ of size $d$ that is the quantity $\max\{|\lambda_i(M)|,\ i=1,\ldots,d\}$ where $|\cdot|$ denotes the modulus of a complex number.

\section{Problem statement}
In this paper, we are interested in proving automatically some properties on a discrete-time affine system. We start by briefly recalling the notion of affine systems and their reachable values set. Then we present the optimization problem that we have to solve to prove or disprove a property on an affine system.

\subsection{Affine systems}

We can represent the evolution of an affine system by the following relation:
\begin{equation}
\label{context}
x_0\in \xin,\ \forall\, k\in\nn,\ x_{k+1}=A x_k + b  
\end{equation}
where:
\begin{itemize}
\item $A$ is a non-zero square matrix of size $d\times d$;
\item $b$ is vector of $\rd$;
\item  $\xin$ is a non-empty polytope (bounded polyhedra). 
\end{itemize}
We insist on the fact that the initial values are represented by an infinite bounded set. It can be interpreted as a set of perturbations, non-determinism, different cases...

It is well-known that, for all $k\in\nn$, the term of the sequence defined at Equation~\eqref{context} can be expressed as follows:
\[
x_k=A^k x_0+ \sum_{i=0}^{k-1} A^i b,\ x_0\in\xin
\]

From the latter expression of the state-variables, we can define the reachable values set $\rea$ of the affine system presented at Eq.~\eqref{context} :
\begin{equation}
\label{reach}
\rea=\bigcup_{k\in \nn} \left(A^{k}(\xin)+\sum_{i=0}^{k-1} A^i b\right)
\end{equation}
where $A^i$ and $A^k$ denote the number of image iterates of $A$ (powers of matrix $A$) . 

\subsection{The verification problem}
In this paper, we are interested in proving properties on affine systems. We are focusing on the properties supposed to be true for all possible values of the state-variable $x_k$ i.e. for all $k\in\nn$ $x_k$ has to satisfy the property. Since, we can represent a property as to belong to some set $C\subset \rd$, to prove a property is equivalent to prove that, $\rea\subseteq C$. In this paper, we consider the sets $C$  of the form $\{x\in\rd, x^\intercal Q x+q^\intercal x\leq \alpha\}$ where $Q$ is a symmetric matrix of size $d\times d$ and $q\in\rd$. The real number $\alpha$ can be given or proved to be finite (for example to prove the boundedness).  Thus, a verification problem can be viewed as an optimization problem. Indeed, to prove $\rea\subseteq \{x\in\rd, x^\intercal Q x+q^\intercal x\leq \alpha\}$ is equivalent to prove that
$\sup_{x\in\rea} x^\intercal Q x+q^\intercal x\leq \alpha$.
Then to prove the property boils down to compute: 
\begin{equation}
\label{pbopt}
\begin{array}{ll}
&\displaystyle{\sup_{x\in\rea} x^\intercal Q x+q^\intercal x}\\
=&\displaystyle{\sup_{k\in\nn}\sup_{x_0\in\xin}  \left(A^k x_0+ \sum_{i=0}^{k-1} A^i b \right) Q \left( A^k x_0+ \sum_{i=0}^{k-1} A^i b\right) +q^\intercal \left(A^k x_0+ \sum_{i=0}^{k-1} A^i b\right)}\enspace .
\end{array}
\end{equation} 

If the exact optimal value of Problem~\eqref{pbopt} can be computed then we can prove or disprove a property whereas an over-approximation can only prove a property: a too loose over-approximation i.e. greater than $\alpha$ does not imply that the property is false. 

The problem in the computation of the optimal value of Problem~\eqref{pbopt} resides, first, in the infinite number of quadratic optimization problems that we have to solve. In a second time, the quadratic optimization problems are non-necessarily concave and thus can be difficult to solve. 

%Making some assumptions can lead to make the problem solvable in a finite number of operations. 
\section{Results}

This section contains the main contribution of the paper i.e. the computation of the optimal value of Problem~\eqref{pbopt}. This latter computation uses a discretization of initial values set and the computation of a finite integer after which we know that the optimal cannot be reached. In this section, we begin to recall some basic results that we need in our development. We then study the case of linear systems i.e. where $b=0$ in Eq.~\eqref{context}. Finally, we show how to use the linear case to solve the case where the system is affine.   
\subsection{Basic notions}

For a given square matrix $M$, the matrix $P$ satisfies the discrete Lyapunov equation if and only $P\succ 0$ and $P-M^\intercal P M\succeq 0$. If $\rho(M)<1$, then the discrete Lyapunov equation has at least one solution. Moreover, in this case, we can find $P\succ 0$ such that $P-M^\intercal P M\succ 0$.  

For the matrix $A$ of the affine system considered at Eq.~\eqref{context}, we introduce the set $\lyap{A}$ of the  solutions  of the discrete Lyapunov equation i.e.:
\[
\lyap{A}=\{P\in\sym \mid P\succ 0,\ P-A^\intercal P A\succ 0\}\enspace .
\]
Hence, $\rho(A)<1$ ensures that $\lyap{A}$ is non-empty. More precisely, $\rho(A)<1$ if and only if for all positive definite matrices $R$ there exists a unique positive definite matrix $P$ such that $P-A^\intercal P A=R$. \ForAuthors{reference sur stein equation}

To prove some results, we need to recall some basic results presented as lemmas. The first one involves a double inequality between quadratic forms and Euclidean norm. When the quadratic form is positive definite then the double inequality proves the norm equivalence between the norm defined by the quadratic form and the Euclidean norm with explicit constants. 
\begin{lemma}
\label{lemma1}
Let $M$ be in $\sym$. We recall that $\lmax{M}$ (resp. $\lmin{M}$) denotes the greatest eigenvalue of $M$ (resp. the smallest eigenvalue of $M$) then, for all $x\in \rd$:
\begin{equation}
\label{eigineg}
\lmin{M}\norm{x}_2^2\leq x^\intercal M x\leq \lmax{M} \norm{x}_2^2
\end{equation}
where $\norm{\cdot}_2$ is the Euclidean norm. 
\end{lemma}
Inequalities~\eqref{eigineg} can be formulated in term of positive semi-definiteness:
\[
\lmin{M}\Idd\preceq M\preceq \lmax{M}\Idd
\]

We recall Weyl's inequalities~\cite{horn1990matrix} that provide inequalities for the eigenvalues of the sum of two symmetric matrices and the sum of the eigenvalues of each matrix.  
\begin{lemma}[Weyl's inequalities]
\label{le}
Let $M$ and $N$ be symmetric matrices. We have, for all $\ell\in\{1,\ldots,d\}$:
\[
\lambda_\ell(M)+\lmin{N}\leq \lambda_\ell(M+N)\leq \lambda_\ell(M)+\lmax{N}
\]
\end{lemma}
The following lemma recalls that, when we maximize a convex function over a polytope, it suffices to consider the values of the function at the extreme points. 
\begin{lemma}[Maximisation of a convex function over a polytope]
\label{lemma2}
Let $C$ be a polytope and $f:\rd\to\rd$ a convex function. Then:
\[
\max_{x\in C} f(x)=\max_{x\in \mathcal{E}(C)} f(x)
\]
where $\mathcal{E}(C)$ denotes the finite set of the extreme points (vertices) of $C$.
\end{lemma}
Note that the result also holds for convex compacts sets.  
%\begin{lemma}[]

%\end{lemma}
\subsection{Verification Linear Time-Invariant Discrete-time Systems}
\label{mainsub}
Now we come back to the verification problem presented at~\eqref{pbopt}. In this subsection, we suppose that the system in linear i.e. $b=0$ in~\eqref{context}. We will show at Subsection~\ref{affine} that the case $b\neq 0$ can be reduced to the linear case.

Since $b=0$, Problem~\eqref{pbopt} becomes :
\[
\sup_{k\in\nn}\sup_{x_0\in\xin} x_0^\intercal (A^k)^\intercal Q A^k x_0+q^\intercal A^k x_0\enspace .
\]

The main goal of this subsection is to {\bf compute the smallest possible integer} $\mathbf K$ such that:
\[
 \sup_{x\in\rea} x^\intercal Q x+p^\intercal x=\sup_{k\in\{0,\ldots,\mathbf K\}}\sup_{x_0\in\xin} x_0^\intercal (A^k)^\intercal Q A^k x_0+q^\intercal A^k x_0\enspace .
\]

Without any assumption on $Q$, the computation of  $\sup_{x_0\in\xin} x_0^\intercal (A^k)^\intercal Q A^k x_0+q^\intercal A^k x_0$ for all $k\in\{0,\ldots,K\}$ is still difficult. Then we make the following assumption : 
\begin{assumption}
\label{assum1}
The matrix $Q$ is non-null and positive semi-definite.
\end{assumption}

From Assumption~\ref{assum1}, Problem~\eqref{pbopt} has a finite optimal value if either $\rea$ is bounded or for all 
$x_0\in\xin$ that generates an unbounded sequence, the sequence $x_k=A^k x_0$ lies eventually in the null space of $Q$ ($x_k^\intercal Q x_k=0$ for sufficiently large integers $k$) and satisfies eventually $q^\intercal A^k x_0\leq \beta$ for some $\beta\in\rr$ .  We will consider bounded reachable values set. This latter restriction will not be enough for our development. Using Jordan block decompositions, the reachable values set can be bounded even if the spectral radius of $A$ is equal to 1. The construction of our $K$ depends on the fact that there exists a matrix norm $N$ such that $N(A)<1$. This condition is not compatible with the case where the spectral radius of $A$ is equal to 1.

\begin{assumption}
\label{assum2}
The spectral radius $\rho(A)$ of $A$ is strictly smaller that 1.
\end{assumption}

Assumption~\ref{assum2} ensures that $\lyap{A}\neq \emptyset$. Since for all $P\in\lyap{A}$, $P\succ 0$, we can define a norm on $\rd$ associated with $P\in\lyap{A}$ as follows: for all $x\in\rd$:
\[\norm{x}_P:=\sqrt{x^\intercal P x}\enspace. \]
For any norm $\norm{\cdot}$, we can define the operator norm as $\norm{A}=\max_{x\neq 0} x^\intercal A x/ x^\intercal x$. In the case where the norm is constructed from a positive definite matrix, we can compute $\norm{A}_P$ as follows:
\begin{equation}
    \norm{A}_P^2=\max_{x\neq 0} \dfrac{x^\intercal A^\intercal P A x}{x^\intercal P x}=\inf\{\alpha>0\mid \alpha P-A^\intercal P A\succeq 0\}
\end{equation}

Let $t>0$. We introduce the following set :  
\[
\conq(t)=\{P\in\sym\mid tP-Q\succeq 0\}
\]
Since, under Assumption~\ref{assum1}, $P\in\conq(t)$ implies that $P$ is positive semi-definite, then $\conq(t)$ is a pointed convex cone. Moreover, for all positive definite matrix $P$, there exists $t>0$ such that $P\in \conq(t)$. 

Then, we introduce a related set, which is parameterized by $P\in \sym$.
\[
\cont(P)=\{t>0\mid P\in\conq(t) \}=\{t>0\mid tP-Q\succeq 0\}
\]

Let us introduce the family $\lyat{A,Q}$ parameterized by positive numbers $t$ of sets of solutions of discrete Lyapunov equations defined as follows:
\[
\lyat{A,Q}=\conq(t)\cap\lyap{A}=\{P\succ 0\mid tP-Q\succeq 0,\ P-A^\intercal P A\succ 0\}\enspace. 
\]
Note that, since the set of positive definite matrix is a cone, we get the following equivalence :
\begin{equation}
P\in\lyat{A,Q}\iff tP\in\lyaun\enspace.
\end{equation}
 

\begin{comment}
Finally, we need a third related set . For all $P\succ 0$, we define:

\[
\lyaa{P}=\{t>0\mid P\in\lyat{A,Q}\} 
\]
\end{comment}
Actually we can bound $\cont(P)$ from below. Since $P$ is positive definite, we can use the inverse of the square root $P^{-1/2}$ of $P$ . We recall that this matrix is defined from the spectral decomposition of $P=U D U^\intercal$ where $D$ is a diagonal  matrix of ordered (strictly positive) eigenvalues $\lambda_k(P)$ and $U$ is an orthogonal matrix i.e. $U U^\intercal = U^\intercal U=\Idd$.   The matrix  $P^{-1/2}$ is thus defined by 
$U D^{-1/2} U^\intercal$ where $D^{-1/2}$ is the diagonal matrix whose the diagonal elements are equal $\lambda_k(P)^{-1/2}$. This easy to see that $P^{-1/2} P^{-1/2}=P^{-1}$. 

\begin{prop}
\label{propcont}
For all $P\succ 0$, for all $t\in\cont(P)$, $t\geq \lmax{P^{-1/2} Q P^{-1/2}}$.
\end{prop}
\begin{proof}
Let $P\succ 0$, let $t\in\cont(P)$. Let $x\in\rd$, $x\neq 0$. We have 
$x^\intercal Q x\leq t x^\intercal P x$ and thus $(x^\intercal Q x)(x^\intercal P x)^{-1}\leq t$. Finally:
$\sup_{x\neq 0}(x^\intercal Q x)(x^\intercal P x)^{-1}\leq t $. Writing $y=P^{1/2}x$ ( recall that $P^{1/2}$ is invertible as $P\succ 0$), we obtain :
$\sup_{y\neq 0}(y^\intercal P^{-1/2}Q P^{-1/2}y)(y^\intercal y)^{-1}\leq t $. However, it is well-know that
$\sup_{z\neq 0} (z^\intercal M z)(z^\intercal z)^{-1}=\lmax{M}$. In fact, $\lmax{M}$ is achieved for an eigenvector associated with $\lmax{M}$. Hence, 
$\sup_{y\neq 0} (y^\intercal P^{-1/2}Q P^{-1/2}y)(y^\intercal y)^{-1}=\lmax{P^{-1/2} Q P^{-1/2}}$. Finally $\lmax{P^{-1/2} Q P^{-1/2}}P-Q\succeq 0$ is a direct consequence of Lemma~\ref{lemma1}. 

\end{proof}
\begin{comment}
\begin{prop}
For all matrix $A$ of size $d\times d$ such that the spectral radius is strictly smaller than 1. For all symmetric matrix $Q$ of size $d\times d$: 
\begin{enumerate}
\item For all positive reals $t,t'$ such that $t\leq t'$, $\displaystyle{\lyat{A,Q}}\subseteq \displaystyle{\mathcal{L}_{A,Q}(t')}$;
%\item For all $P\in\lyap{A}$, $P\in\displaystyle{\mathcal{L}_{\bar t}(A,Q)}$ with $\bar t=\lambda_d(P)\lambda(Q)^{-1}$;
\item For all $P\succ 0$, $\lmin{P}^{-1}\lmax{Q}\in\conq(P)$;
\item $\displaystyle{\bigcup_{t>0} \lyat{A,Q}}=\displaystyle{\lyap{A}}$.
\end{enumerate}
\end{prop}
\end{comment}
To compute our $\bigk$, we introduce a new notation and a new assumption. 
 \begin{assumption}
\label{assumR}
There exists $k\in\nn$ such that\[\min\left\{\sup_{x\in\xin} x^\intercal Q x , \sup_{x\in\xin} x^\intercal (A^k)^\intercal Q A^k x+q^\intercal A^k x\right\}\] is strictly positive.
\end{assumption}

We will need the following notation:
\[
\ks:=\inf\left\{k\in\nn\mid \min\left\{\sup_{x\in\xin} x^\intercal Q x , \sup_{x\in\xin} x^\intercal (A^k)^\intercal Q A^k x+q^\intercal A^k x\right\}>0\right\}
\]
and
\[
\lfrak:= \min\left\{\sup_{x\in\xin} x^\intercal Q x , \sup_{x\in\xin} x^\intercal (A^{\ks})^\intercal Q A^{\ks}k x+q^\intercal A^{\ks}x\right\}
\]

Note that Assumption~\ref{assum1} is not sufficient to ensure the validity of Assumption~\ref{assumR}. The matrix $Q$ is only supposed to be positive semi-definite and thus $\sup_{x\in\xin} x^\intercal Q x$ can be null. Moreover, $\lfrak$ can be negative since $q^\intercal A^k x$ can be negative on $\xin$. Strongest assumptions can be made : the global positivity of $x^\intercal (A^k)^\intercal  Q A^k x+q^\intercal A^k x$ which is equivalent to check whether a matrix is definite positive or a copositivity condition relying $Q,q$ and $\xin$. 

%For a symmetric matrix $M$, the notation $\mu_{\xin}(M)$ stands for $\sup_{x\in\xin} x^\intercal M x$. Recall that, since $\xin$ is a polytope, from Lemma~\ref{lemma2}, $\mu_{\xin}(M)$ can be exactly computed from a finite number of evaluations of $x^\intercal M x$.

Now, we define the key numbers that we need to solve the verification problem. We explain latter in the proof how they are constructed. Moreover, we will study later on numerical examples how much they are accurate.  

\begin{comment}
Let $t>0$ and $P\in\lyat{A,Q}$. Let us define the following formula :
\begin{equation}
\label{kappat}
\kappa_t(P)=  \dfrac{\ln\left(\mu_{\xin}(Q)\mu_{\xin}(P)^{-1}t^{-1}\right)}{\ln\left(\norm{A}_P^2\right)}
\end{equation}

Let $P\in\lyap{A}$. We define the following formula :
\begin{equation}
\label{kappainf}
\kappa_\infty(P)= \dfrac{\ln\left(\mu_{\xin}(Q)\mu_{\xin}(P)^{-1}\lambda_d(P)\lambda_1(Q)^{-1}\right)}{\ln\left(\norm{A}_P^2\right)}
\end{equation}
\end{comment}

Let $t>0$ and $P\in\lyap{A}$ such that $P\in \lyat{A,Q}$. Let us define the following formula :
\begin{equation}
\label{intgfond}
K(t,P)=\left\lfloor \dfrac{\ln\left[\left(\sqr{\lfrak+\vqQ(t,P)^2}-\vqQ(t,P)\right)\left(\sqr{t}\mu(P)\right)^{-1}\right]}{\ln\left(\norm{A}_P\right)}\right\rfloor+1
\end{equation}
where 
\[
\vqQ(t,P):=\dfrac{\norm{q}_2 }{2\sqr{t\lmin{P}}}\quad \text{ and } \mu(P)=\sup_{x\in\xin} \sqr{x^\intercal P x}
\]
\begin{comment}
\begin{equation}
K_t=\left\lfloor \dfrac{\ln\left(\mu(Q)^2\left(t\mu(P)^{2}+\mu(P)\lambda_d(P)^{-1/2}\norm{q}_2\right)^{-1}\right)}{\ln\left(\norm{A}_P\right)}\right\rfloor+1
\end{equation}

\begin{equation}
K_t=\left\lfloor \dfrac{\ln\left(\left[L+4\norm{q}_2^2\lmin{P}^{-1}t^{-2}\mu(P)^{-1}\right]^{1/2}-
\left(2t^{-1}\mu(P)^{1/2}\lmin{P}^{-1/2}\norm{q}_2\right)\right)}{\ln\left(\norm{A}_P\right)}\right\rfloor+1
\end{equation}

Let $P\in\lyap{A}$. We define the following formula :
\begin{equation}
K_0=\left\lfloor \dfrac{\ln\left(\mu(Q)^2\left(\lmin{P}^{-1}\lmax{Q}\mu(P)^{2}+\mu(P)\lambda_d(P)^{-1/2}\norm{q}_2\right)^{-1}\right)}{\ln\left(\norm{A}_P\right)}\right\rfloor+1
\end{equation}

\begin{equation}
K_\infty=\left\lfloor \dfrac{\ln\left(\mu(Q)^2\left(\lmax{P^{-1/2} Q P^{-1/2}}\mu(P)^{2}+\mu(P)\lambda_d(P)^{-1/2}\norm{q}_2\right)^{-1}\right)}{\ln\left(\norm{A}_P\right)}\right\rfloor+1
\end{equation}

\begin{comment}
Let write hypothesis:
\begin{equation}
\label{hypo1}
P\succ 0,\ \lambda_1(Q) P- Q\succeq 0,\ P-A^\intercal P A\succ 0
\end{equation}

\begin{equation}
\kappa_1(P):=\ln\left(\alpha(Q,\xin) \alpha(P,\xin)^{-1}\lambda_1(Q)^{-1}\right) \left(\ln(\norm{A}_P^2)\right)^{-1}
\end{equation}

\begin{equation}
\label{hypo2}
P\succ 0,\ P-A^\intercal P A\succ 0
\end{equation}

\begin{equation}
\kappa_2(P):=\log\left(\alpha(Q,\xin) \alpha(P,\xin)^{-1}\lambda_{d}(P)\lambda_1(Q)^{-1}\right) \left(\log(\norm{A}_P^2)\right)^{-1}
\end{equation}
\end{comment}

\begin{prop}
For all $t>0$, $P\in \lyap{A}$ such that $P\in \lyat{A,Q}$, $1\leq K(t,P)< +\infty$.  
\end{prop}

It suffices to show that both numerator and denominator are negative and finite. Since we use the natural logarithm, this is equivalent to show that the arguments of the natural logarithm of the numerators lie in the interval $(0,1]$ and $\norm{A}_P$ lies in the interval $(0,1)$ for all $P\in\lyap{A}$. 
%Since $\lyat{A,Q}\subseteq \lyap{A}$, a proof of $\norm{A}_P\in (0,1)$ for $P\in\lyap{A}$ is only required.

\begin{lemma}
\label{lyapnorm}
For all $P\in\lyap{A}$, $0<\norm{A}_P<1$. 
\end{lemma}

\begin{proof}
Let $P$ such that $P\succ 0$ and $P-A^\intercal P A\succ 0$.  First, the matrix $A$ is not null then its spectral radius is strictly positive. Then since $\norm{\cdot}_P$ is a matrix norm, $0<\rho(A) \leq \norm{A}_P$.

Secondly, since $P-A^\intercal P A\succ 0$, $\norm{A}_P\leq 1$. Thus, to prove $\norm{A}_P<1$, it suffices to exhibit $\varepsilon>0$ such that $(1-\varepsilon) P-A^\intercal P A\succeq 0$ with $0<\varepsilon<1$. 

Let us write $\varepsilon=\lmin{P-A^\intercal P A} \lmax{P}^{-1}$. Let us prove that $0<\varepsilon<1$ and $(1-\varepsilon) P-A^\intercal P A\succeq 0$.  Since $P-A^\intercal P A\succ 0$, $\lmin{P-A^\intercal P A}>0$ and from $P\succ 0$ we conclude that $\varepsilon >0$. Since $P=P-A^ \intercal P A +A^\intercal P A$, we have, from Weyl's inequalities, $\lmin{P-A^\intercal P A}+\lmax{A^\intercal P A}\leq \lmax{P}$. Now, $A^\intercal P A\succeq 0$ from $P\succ 0$ and then $\lmax{A^\intercal P A}\geq 0$. We conclude that $\varepsilon\leq 1$. Now, if $\lmin{P-A^\intercal P A}=\lmax{P}$ i.e. $\varepsilon=1$, we have 
$\lmax{A^\intercal P A}=0$ and then $x^\intercal A^\intercal P A x=0$ for all $x\in \rd$ and $A$ is the null matrix. 
Finally, $\varepsilon<1$. 

Now from Lemma~\ref{lemma1}, $\varepsilon P=P\lmax{P}^{-1}\lmin{P-A^\intercal P A}\preceq \lmin{P-A^\intercal P A}Id_d\preceq 
P-A^\intercal P A$ which implies that $(1-\varepsilon) P -A^\intercal P A\succeq 0$. 
\end{proof}

Now we prove that the argument of the natural logarithm at the numerator appearing in $K(t,P)$ lies in $(0,1]$. 
%Since $P\in\lyap{A}$ implies that $P\in\displaystyle{\mathcal{L}_{\bar t}(A,Q)}$ with $\bar t=\lambda_d(P)\lambda(Q)^{-1}$, it suffices to prove that, for all $P\in\lyat{A,Q}$, $ \mu_{\xin}(Q)\mu_{\xin}(P)^{-1}t^{-1}\in (0,1]$.

\begin{comment}
\begin{lemma}
For all $P$ satisfying Hypothesis~\eqref{hypo1}, $0\leq \alpha(Q,\xin) \alpha(P,\xin)^{-1}\lambda_1(Q)^{-1}\leq 1$. 
For all $P$ satisfying Hypothesis~\eqref{hypo2}, $0\leq \alpha(Q,\xin) \alpha(P,\xin)^{-1}\lambda_{d}(P)\lambda_1(Q)^{-1}\leq 1$.    
\end{lemma}
\end{comment}

\begin{lemma}
For all $t>0$ and $P\in\lyap{A}$ such that $P\in\lyat{A,Q}$: \[
\left(\lfrak+\vqQ(t,P)^2)^{1/2}-\vqQ(t,P)\right) t^{-1/2}\mu(P)^{-1}\in (0,1]\enspace .
\]
\end{lemma}

\begin{proof}
First $t>0$ and $P\succ 0$ then $t^{-1/2}\mu(P)^{-1}>0$ and $\vqQ(t,P)\geq 0$. Using Assumption~\ref{assumR}, we get $(\lfrak+\vqQ(t,P)^2)^{1/2}-\vqQ(t,P)> \vqQ(t,P)-\vqQ(t,P)=0$. We conclude that $\left((\lfrak+\vqQ(t,P)^2)^{1/2}-\vqQ(t,P)\right) t^{-1/2}\mu(P)^{-1}>0$. 

Now, since $\lfrak$, $\vqQ(t,P)$ are non-negative and for all $a,b\geq 0$, $\sqrt{a+b}\leq \sqrt{a}+\sqrt{b}$  then : 
$(\lfrak+\vqQ(t,P)^2)^{1/2}\leq \lfrak^{1/2}+\vqQ(t,P)$. Hence : 
\[
\begin{array}{lll}
&\left((\lfrak+\vqQ(t,P)^2)^{1/2}-\vqQ(t,P)\right) t^{-1/2}\mu(P)^{-1}& \\
\leq &\lfrak^{1/2} t^{-1/2}\mu(P)^{-1} & \\
\leq &(\displaystyle{\sup_{x\in\xin} x^\intercal Q x})^{1/2} t^{-1/2}\mu(P)^{-1} & \text{ from the def. of } \lfrak
\end{array}
\]

Since $t>0$ and $P\in\lyap{A}$ satisfy $P\in\lyat{A,Q}$, then $t P-Q\succeq 0$. It follows that 
$t x^\intercal P x\geq x^\intercal Q x$ for all $x\in \xin$. Taking the supremum over $\xin$ leads to $(\sup_{x\in\xin} x^\intercal Q x)\mu(P)^{-2}t^{-1} \leq 1$. 
\begin{comment}
Note that  $\alpha(Q,\xin) \alpha(P,\xin)^{-1}\lambda_1(Q)^{-1}$ is nonnegative since $P$ and $Q$ are positive semi-definite and thus each factor of the latter product is nonnegative.

Applying twice Lemma~\ref{lemma1}, we get $Q\preceq \lambda_1(Q) Id\preceq \lambda_1(Q)\lambda_d(P)^{-1} P$. Now taking $x\in\xin$,
we conclude that $\alpha(Q,\xin) \alpha(P,\xin)^{-1}\lambda_{d}(P)\lambda_1(Q)^{-1}\leq 1$. The fact that the latter product is nonnegative follows readily from the fact that $P$ and $Q$ are positive semidefinite.
\end{comment}
\end{proof}

\begin{prop}
The following assertions are true:
\begin{itemize}
\item For all $P\in\lyap{A}$, the function defined on $\cont(P)$, $t\mapsto K(t,P)$ is increasing. Then : 
\begin{equation}
\label{infsolved}
\inf_{P\in\lyap{A}} \inf_{t\in\cont(P)} K(t,P)=\inf_{P\in\lyap{A}}K(\lmax{P^{-1/2} Q P^{-1/2}},P)
\end{equation}
\item For all $t>0$, for all $P\in\lyat{A,Q}$, $K(t,P)=K(1,tP)$ and thus:
\[
\inf_{t>0} \inf_{P\in\lyat{A,Q}} K(t,P)=\inf_{P\in\lyaun} K(1,P)
\]
\end{itemize}
\end{prop}

\begin{proof}
Let $P\in\lyap{A}$. Let $t\in\cont(P)$. The integer part is increasing then we have to prove that the argument of the integer part is increasing in $t$. From Lemma~\ref{lemma2}, we know that $\ln{\norm{A}_P}<0$. Hence, since the natural logarithm is increasing it suffices to show that $\varphi:t:\mapsto \left(\sqr{\lfrak+\vqQ(t,P)^2}-\vqQ(t,P)\right)\left(\sqr{t}\mu(P)\right)^{-1}$ is decreasing. However :
\[
\begin{array}{lll}
\varphi(t)&=&\dfrac{\lfrak}{\left(\sqr{\lfrak+\vqQ(t,P)^2}+\vqQ(t,P)\right)\sqr{t}\mu(P)}\\
\\
&=&\dfrac{\lfrak}{\left(\sqr{\lfrak+\dfrac{\norm{q}_2^2 }{4t\lmin{P}}}+\dfrac{\norm{q}_2 }{2\sqr{t\lmin{P}}}\right)\sqr{t}\mu(P)}\\
\\
&=&\dfrac{\lfrak}{\left(\sqr{t\lfrak+\dfrac{\norm{q}_2^2 }{4\lmin{P}}}+\dfrac{\norm{q}_2 }{2\sqr{\lmin{P}}}\right)\mu(P)}
\end{array}
\]
We conclude that $t\mapsto \varphi(t)$ is decreasing as an inverse of an increasing function. 
Finally, Eq.~\eqref{infsolved} follows from Prop.~\ref{propcont} and $t\mapsto K(t,P)$ is increasing for all $P\in\lyap{A}$.  
\end{proof}

We now present the main result of the paper. %Note that again, we use the fact that $P\in\lyap{A}$ implies that $P\in\displaystyle{\mathcal{L}_{\bar t}(A,Q)}$ with $\bar t=\lambda_d(P)\lambda(Q)^{-1}$ to present a result for $\lyat{A,Q}$.

\begin{theorem}
\label{thfond}
Let us define \[\bigk=\min\left\{\inf_{t>0}\inf_{P\in\lyat{A,Q}} K(t,P),\inf_{P\in\lyap{A}} K(\lmax{P^{-1/2}QP^{-1/2}},P)\right\}\enspace .\] Let $k\geq \bigk$. Then : 
\[
\max_{x\in \xin} x^\intercal (A^k)^\intercal Q A^k x+q^\intercal A^k x\leq \lfrak
\]
\end{theorem}

\begin{proof}
Let $t>0$ and $P\in\lyap{A}$ such that $P\in\lyat{A,Q}$. Let also $k\in\nn$ and $x\in\xin$. We have:
\[
x^\intercal (A^k)^\intercal Q A^k x  
\leq  t \norm{A^k x}_P^2\leq t\norm{A}^{2k}_P \norm{x}^2_P
\leq t\norm{A}_P^{2k} \mu(P)^2
\]
The first inequality comes from the definition of $\lyat{A,Q}$, the second from the matrix norm definition and the last from the definition of $\mu(P)$ (see Eq.~\eqref{intgfond}).

We also have, for all $x\in\xin$:
\[
q^\intercal A^k x
\leq \norm{q}_2 \norm{A^k x}_2\leq \dfrac{\norm{q}_2 \norm{A^k x}_P}{\sqr{\lmin{P}}} 
\leq \dfrac{\norm{q}_2\norm{A}_P^{k} \mu(P)}{\sqr{\lmin{P}}}
\]
The first inequality comes from Cauchy-Schwarz, the second from Lemma~\ref{lemma1} and the last from the matrix norm definition and the definition of $\mu(P)$. 

Summing the two parts leads to :
\[
x^\intercal (A^k)^\intercal Q A^k x+q^\intercal A^k x\leq \left(\sqrt{t}\norm{A}_P^k\mu(P)+\vqQ(t,P)\right)^2-\vqQ(t,P)^2
\]
where $\vqQ$ is defined at Eq.~\eqref{intgfond}. Then, $ \left(\sqrt{t}\norm{A}_P^k\mu(P)+\vqQ(t,P)\right)^2-\vqQ(t,P)^2\leq \lfrak$ implies that $ \max_{x\in \xin} x^\intercal (A^k)^\intercal Q A^k x+q^\intercal A^k x\leq \lfrak$. Now, we remark that  $\left(\sqrt{t}\norm{A}_P^k\mu(P)+\vqQ(t,P)\right)^2-\vqQ(t,P)^2\leq \lfrak$ is equivalent to :
\[
\norm{A}_P^k\leq \left(\sqr{\lfrak+\vqQ(t,P)^2}-\vqQ(t,P)\right)\left(\sqr{t}\mu(P)\right)^{-1}
\]
Using the natural logarithm and Lemma~\ref{lyapnorm}, the condition  $k\geq K(t,P)$ is sufficient for the latter inequality .  The latter proof is valid for all couple $t>0$ and $P\in\lyap{A}$ such that $P\in\lyat{A,Q}$. So it remains true for   $\bt>0$ and $\bP\in\lyap{A}$ such that $P\in\lyat{A,Q}$ and $\bigk=K(\bt,\bP)$. 
\end{proof}
We recall that $\lfrak$ is smaller than $\max_{x\in\xin} x^\intercal Q x+q^\intercal x$. Hence, the optimal value of Problem~\ref{pbopt} is greater than $\lfrak$ since $\xin\subseteq \rea$. We conclude that, following Th.~\ref{thfond}, the optimal value of Problem~\ref{pbopt} is attained for powers of $A$ between 0 and $\bigk$.

\begin{corollary}
The following statement is true :
 \[
\max_{y\in\rea} y^\intercal Q y+q^\intercal y=\max_{0\leq k\leq \bigk-1} \max_{x\in \mathcal{E}(\xin)} x^\intercal (A^k)^\intercal Q A^k x+q^\intercal A^k x
\]
\end{corollary}

\begin{proof}
Let $k\in\nn$. We define :
\[
\nu_k:x\mapsto x^\intercal (A^k)^\intercal Q A^k x+q^\intercal A^k x 
\]
Using extreme points instead of the whole set $\xin$ is a direct consequence of the convexity of the functions $\nu_k$ (Assumption~\ref{assum1}) and Lemma~\ref{lemma2}.
 \[
 \begin{array}{lll}
\displaystyle{\max_{y\in\rea} y^\intercal Q y+q^\intercal y}
&=&\displaystyle{\max_{x\in \mathcal{E}(\xin)}\max\left\{\max_{0\leq k\leq \bigk-1} \nu_k(x),\max_{k\geq \bigk} \nu_k(x)\right\}}\\
&=&\displaystyle{\max\left\{\max_{0\leq k\leq \bigk-1}\max_{x\in \mathcal{E}(\xin)} \nu_k(x),\lfrak\right\}}
\end{array}
\]
The conclusion follows from the fact that  $\lfrak\leq \max_{x\in \mathcal{E}(\xin)} \nu_0(x)$.
\end{proof}
The integer $\bigk$ is the best integer than we can get in theory. In practice, we cannot compute this integer since we cannot solve the minimization problems :
\[
\inf_{t>0}\inf_{P\in\lyat{A,Q}} K(t,P)\text{ and }\inf_{P\in\lyap{A}}K(\lmax{P^{-1/2} Q P^{-1/2}},P)
\]
In practice, for the moment, we only compute two integers : $K( \lmax{Q},P)$ where $P$ is an optimal solution of a perturbation of the minimization problem : 
\begin{equation}
\label{minlmaxQ}
\inf\{\lmax{P}\mid P\in \lyam{A,Q}\}
\end{equation}
and $K(\lmax{P^{-1/2} Q P^{-1/2}},P)$ where $P$ is an optimal solution of a perturbation of the minimization problem :
\begin{equation}
\label{minlyap}
\inf\{\lmax{P}\mid P\in\lyap{A}\}\enspace .
\end{equation}
We take after the minimum of the  two integers. We come back latter on the perturbation of the two minimization problems at Section~\ref{computations}.
\subsection{From linear systems to affine ones}
\label{affine}
Let us consider the same problem where we replace the linear dynamics by an affine one:

\[
x_{k+1}=A x_k+b,\ x_0\in \xin
\]

where $A$ is still a $d\times d$ matrix and $b$ a vector of $\rd$. We denote by $\rea$ the set of all possible $x_k$ being an element of the trajectory of such $x_0\in\xin$. We still consider the optimization problem:
\[
\sup_{x\in\rea} x^\intercal Q x+q^\intercal x
\]

We can reformulate an affine system with powers of the matrix $A$ and initial vectors: 

\[
x_{k}=A^k x_0+\sum_{i=0}^{k-1} A^i b,\ x_0\in \xin
\]
This latter leads to the optimization problem:
\[
\sup_{k\in\nn} \sup_{x_0\in\xin} \left(A^k x_0+\sum_{i=0}^{k-1} A^i b\right)^\intercal Q  \left(A^k x_0+\sum_{i=0}^{k-1} A^i b\right)+q^\intercal  \left(A^k x_0+\sum_{i=0} A^i b\right)
\]
From Assumption~\ref{assum2}, $Id-A$ is invertible. Let for all $k\in\nn$, $y_k=x_k-(Id-A)^{-1} b$. It is well-known that the sequence $(y_k)_{k\in\nn}$ satisfies $y_{k+1}=A y_k$ for all $k\in\nn$. Then we get the new optimization problem : 
\[
\sup_{k\in\nn} \sup_{y_0\in\xin-B} \left(A^k y_0+B\right)^\intercal Q  \left(A^k y_0+B\right)+q^\intercal  \left(A^k y_0+B\right)
\]
or
\[
\sup_{k\in\nn} \sup_{y_0\in\xin-B} y_0^\intercal (A^k)^\intercal Q  A^k y_0+(2B+q)^\intercal A^k +B^\intercal Q B+q^\intercal B
\]

Finally, we apply the results developed in Subsection~\ref{mainsub} with $Q=Q'$ and $q=2B+q'$. We have to compute $K_t$ and $K_\infty$ using 
\[
\mathfrak{L}'=\min\{\sup_{y\in \xin-B} y^\intercal Q' y,\sup_{y\in \xin-B} y^\intercal Q' y+(2B+q')^\intercal y\}
\]
Assumption~\ref{assum1} becomes $\mathfrak{L}'>0$.
\section{Computation of $\kappa_1$ and $\kappa_2$}
\label{computations}
First for each $\kappa$ we have to solve a semi-definite program to compute a matrix $P$ which satisfies 
a Lyapunov equation.
To compute $\alpha(Q,\xin)$ and $\alpha(P,\xin)$, we use Lemma~\ref{lemma2}, after computing once the vertices of $\xin$. 
To compute the spectral radius of a matrix, there exists a multitude of numerical methods to compute it (Householder, power methods...). Finally, the computation of the norm $\norm{A}_P^2$ can be done using a semi-definite program.

\section{Experiments}

\section{Conclusion and Future Works} 

\bibliographystyle{alpha}
\bibliography{paperbib} 
\end{document}
